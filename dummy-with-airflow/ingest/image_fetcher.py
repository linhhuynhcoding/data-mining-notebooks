import requests
import os
from urllib.parse import urlparse
from pathlib import Path
from dotenv import load_dotenv

# C·∫•u h√¨nh
API_URL = 'https://api.pexels.com/v1/search'  # <- ƒê·ªïi th√†nh URL API th·∫≠t
DOMAINS = ["River in Mountain Forest", "Green Tree Forest", "sea water"]
SAVE_DIR = '../coding/data-mining-notebooks/data/raw/image'
load_dotenv()
API_KEY = os.getenv("API_KEY")

# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)

# H√†m t·∫£i ·∫£nh
def download_image(url: str, save_dir: str):
    try:
        os.makedirs(save_dir, exist_ok=True)

        response = requests.get(url, timeout=10)
        response.raise_for_status()
        filename = os.path.basename(urlparse(url).path)
        filepath = os.path.join(save_dir, filename)
        with open(filepath, 'wb') as f:
            f.write(response.content)
        print(f"‚úÖ ƒê√£ t·∫£i: {filepath}")
    except Exception as e:
        print(f"‚ùå L·ªói v·ªõi {url}: {e}")

def api_fetch_images():
    for i in DOMAINS:
        # G·ªçi API
        try:
            response = requests.get(API_URL + "?query=" + i +"&per_page=10", timeout=10, headers={"Authorization": API_KEY})
            response.raise_for_status()
            data = response.json()  # Gi·∫£ s·ª≠ API tr·∫£ v·ªÅ danh s√°ch URL ·∫£nh
        except Exception as e:
            print(f"L·ªói khi g·ªçi API: {e}")
            exit()
            
        photos = data.get("photos", [])
        print(f"üîç T√¨m th·∫•y {len(photos)} ·∫£nh v·ªõi query")

        for photo in photos:
            img_url = photo.get("src", {})
            if img_url:
                download_image(img_url.get("original", {}), SAVE_DIR + "/" + i.replace(" ", "_"))
            else:
                print(f"‚ö†Ô∏è B·ªè qua ·∫£nh kh√¥ng c√πng domain ho·∫∑c thi·∫øu URL: {img_url}")
